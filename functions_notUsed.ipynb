{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for drawing ROC curve for train and test data\n",
    "# The function still has some problems...\n",
    "\n",
    "def ROC_curve_train_test_label(model, model_name, label):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    #model.fit(X_train_rs, y_train_rs)\n",
    "      \n",
    "    y_train_pred = model.predict(X_train_rs)   \n",
    "    y_train_prob = model.predict_proba(X_train_rs) #Probability estimates for each class\n",
    "    fpr_train, tpr_train, thresholds_train = roc_curve(y_train_rs, y_train_prob[:,label])\n",
    "    #fpr_train, tpr_train, thresholds_train = roc_curve(y_train_rs, y_train_prob[:,label], pos_label=label)\n",
    "    auc_train = round(auc(fpr_train, tpr_train),3)\n",
    "    f1_train = round(f1_score(y_train_rs, y_train_pred, pos_label=label),3)\n",
    "    recall_train = round(recall_score(y_train_rs, y_train_pred, pos_label=label),3)\n",
    "    precision_train = round(precision_score(y_train_rs, y_train_pred, pos_label=label),3)\n",
    "    ax.plot(fpr_train, tpr_train, lw=2, label=f'Train: precison={precision_train}, recall={recall_train}, f1={f1_train}, AUC={auc_train}')\n",
    "    #ax.plot(fpr_train, tpr_train, lw=2, label=f'Train: AUC={auc_train}')\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_prob = model.predict_proba(X_test) #Probability estimates for each class\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_prob[:,label])\n",
    "    #fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_prob[:,label], pos_label=label)\n",
    "    auc_test = round(auc(fpr_test, tpr_test),3)\n",
    "    f1_test = round(f1_score(y_test, y_test_pred, pos_label=label),3)\n",
    "    recall_test = round(recall_score(y_test, y_test_pred, pos_label=label),3)\n",
    "    precision_test = round(precision_score(y_test, y_test_pred, pos_label=label),3)\n",
    "    ax.plot(fpr_test, tpr_test, lw=2, label=f'Test: precison={precision_test}, recall={recall_test}, f1={f1_test}, AUC={auc_test}')\n",
    "    #ax.plot(fpr_test, tpr_test, lw=2, label=f'Test: AUC={auc_test}')\n",
    "    \n",
    "    \n",
    "    if label:\n",
    "        x_title = 'False Positive Rate'\n",
    "        y_title = 'True Positive Rate'\n",
    "    else:\n",
    "        x_title = 'False Negative Rate'\n",
    "        y_title = 'True Negative Rate'\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_yticks([i/20.0 for i in range(21)])\n",
    "    ax.set_xticks([i/20.0 for i in range(21)])\n",
    "    ax.set_xlabel(x_title, fontsize=14)\n",
    "    ax.set_ylabel(y_title, fontsize=14)\n",
    "    ax.set_title(f'ROC Curve for {model_name}, class={label}', fontsize=14)\n",
    "    ax.legend(loc='auto', fontsize=13)\n",
    "    \n",
    "    plt.savefig(f'figures/ROC_Curve_{model_name}_class{label}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
